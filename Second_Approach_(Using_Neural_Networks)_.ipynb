{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1GoiZnAogycZ7fwxTRZamfkn-dKQUYXMi",
      "authorship_tag": "ABX9TyMWM+lYcMWWB1cxAbPj0X8G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjindal19/ennovate-challenge/blob/main/Second_Approach_(Using_Neural_Networks)_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is data Augmentation "
      ],
      "metadata": {
        "id": "F4LoDI1MLrWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLzuK__2Lz6h",
        "outputId": "99579f58-b942-49b2-aa8b-c51d9ed6a9ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40, # rotate image by 10 degrees\n",
        "    zoom_range=0.1, # zoom in/out by 10%\n",
        "    width_shift_range=0.1, # shift image horizontally by 10%\n",
        "    height_shift_range=0.1, # shift image vertically by 10%\n",
        "    brightness_range=[0.7, 1.3], # adjust brightness by random factor between 0.7 and 1.3\n",
        ")\n",
        "training_images = []\n",
        "\n",
        "# Load reference image and training images\n",
        "reference_image = cv2.imread(r'/content/drive/MyDrive/Colab Notebooks/Ennovate Coding Challenge/reference.png')\n",
        "for file in glob.glob(r'/content/drive/MyDrive/Colab Notebooks/Ennovate Coding Challenge/Train/*.JPG'):\n",
        "    training_images.append(cv2.imread(file))\n",
        "\n"
      ],
      "metadata": {
        "id": "WyCpk3KNLwIN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Perform data augmentation on each training image and save it to disk\n",
        "for i, image in enumerate(training_images):\n",
        "    # Expand image dimensions to match batch size of 1\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    \n",
        "    # Generate augmented images and save to disk\n",
        "    j = 0\n",
        "    for batch in datagen.flow(image, batch_size=1, save_to_dir=r'/content/drive/MyDrive/Colab Notebooks/Ennovate Coding Challenge/augmented_data', save_prefix=f'train1{i}', save_format='jpg'):\n",
        "        j += 1\n",
        "        if j == 10: # generate 10 augmented images per original image\n",
        "            break\n"
      ],
      "metadata": {
        "id": "ThngVxUYUSeP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THis is model training"
      ],
      "metadata": {
        "id": "V2_uiq2-ls6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6bMJRI_zlusg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the reference image and the training images\n",
        "ref_image = cv2.imread(r'/content/drive/MyDrive/Colab Notebooks/Ennovate Coding Challenge/reference.png')\n",
        "train_images = []\n",
        "for file in glob.glob(r'/content/drive/MyDrive/Colab Notebooks/Ennovate Coding Challenge/Train/*.JPG'):\n",
        "    scale_percent = 20\n",
        "    src = cv2.imread(file)\n",
        "    width = int(src.shape[1] * scale_percent / 100)\n",
        "    height = int(src.shape[0] * scale_percent / 100)\n",
        "    dsize = (width, height)\n",
        "    train_images.append(cv2.resize(src, dsize))\n",
        "\n",
        "for file in glob.glob(r'/content/drive/MyDrive/Colab Notebooks/Ennovate Coding Challenge/Train/*.jpg'):\n",
        "    scale_percent = 20\n",
        "    src = cv2.imread(file)\n",
        "    width = int(src.shape[1] * scale_percent / 100)\n",
        "    height = int(src.shape[0] * scale_percent / 100)\n",
        "    dsize = (width, height)\n",
        "    train_images.append(cv2.resize(src, dsize))\n",
        "\n",
        "# Creating the input and output pairs for training the model\n",
        "# The input is the noisy image and the output is the reference image\n",
        "X_train = np.array(train_images)\n",
        "y_train = np.array([ref_image for _ in range(1000)])\n",
        "\n",
        "# Normalizing the pixel values to [-1, 1] range\n",
        "X_train = X_train / 127.5 - 1.0\n",
        "y_train = y_train / 127.5 - 1.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR7IoMz0lyOV",
        "outputId": "12693b38-7a71-4cbc-e881-af781b370188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-eef8e0e0ccad>:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_train = np.array(train_images)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Defining the neural network model\n",
        "# The model is a convolutional autoencoder that learns to reconstruct the input image\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Input(shape=(None, None, 3)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), padding=\"same\"))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), padding=\"same\"))\n",
        "model.add(layers.Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), padding=\"same\"))\n",
        "model.add(layers.Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Reshape((1, 1, 16)))\n",
        "model.add(layers.UpSampling2D((2, 2)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.UpSampling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\n",
        "model.add(layers.UpSampling2D((2, 2)))\n",
        "model.add(layers.Conv2D(3, (3, 3), activation=\"tanh\", padding=\"same\"))\n",
        "\n",
        "# Compiling the model with mean squared error loss and Adam optimizer\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n"
      ],
      "metadata": {
        "id": "Y-vpXtWvl09s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training the model for 50 epochs with a batch size of 32\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
        "\n",
        "# Saving the model on the disk\n",
        "model.save(\"denoise_model.h5\")\n"
      ],
      "metadata": {
        "id": "JncOGlw1l49z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is model using"
      ],
      "metadata": {
        "id": "ddmAwHKCmjZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading the model from the disk\n",
        "model = keras.models.load_model(\"denoise_model.h5\")\n",
        "\n",
        "\n",
        "# Loading the input image to be processed\n",
        "input_image = cv2.imread(\"input_image.jpg\")\n",
        "\n",
        "# Normalizing the pixel values to [-1, 1] range\n",
        "input_image = input_image / 127.5 - 1.0\n",
        "\n",
        "# Reshaping the input image to match the model input shape\n",
        "input_image = input_image.reshape(1, *input_image.shape)\n",
        "\n",
        "# Predicting the output image using the model\n",
        "output_image = model.predict(input_image)\n",
        "\n",
        "# Reshaping the output image to match the original image shape\n",
        "output_image = output_image.reshape(*output_image.shape[1:])\n",
        "\n",
        "# Denormalizing the pixel values to [0, 255] range\n",
        "output_image = (output_image + 1.0) * 127.5\n",
        "\n",
        "# Converting the output image to uint8 type\n",
        "output_image = output_image.astype(np.uint8)\n",
        "\n",
        "# Saving the output image on the disk\n",
        "cv2.imwrite(\"output_image.jpg\", output_image)"
      ],
      "metadata": {
        "id": "Kv4FlsnRl7e0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}